{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "chemin_dossier = \"C:/Users/paulm/Documents/Projet 7/Projet7withCSV/data/\" \n",
    "df = pd.read_csv(os.path.join(chemin_dossier, 'processed_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_NaN</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_NaN</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>307499.000000</td>\n",
       "      <td>3.072330e+05</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>278180.518577</td>\n",
       "      <td>0.080729</td>\n",
       "      <td>0.417052</td>\n",
       "      <td>1.687979e+05</td>\n",
       "      <td>5.990260e+05</td>\n",
       "      <td>27108.573909</td>\n",
       "      <td>5.383962e+05</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-16036.995067</td>\n",
       "      <td>63815.045904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.508408</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.214757</td>\n",
       "      <td>0.210773</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>0.473983</td>\n",
       "      <td>0.518446</td>\n",
       "      <td>0.007570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>102790.175348</td>\n",
       "      <td>0.272419</td>\n",
       "      <td>0.722121</td>\n",
       "      <td>2.371231e+05</td>\n",
       "      <td>4.024908e+05</td>\n",
       "      <td>14493.737315</td>\n",
       "      <td>3.694465e+05</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>4363.988632</td>\n",
       "      <td>141275.766519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086085</td>\n",
       "      <td>0.075840</td>\n",
       "      <td>0.499930</td>\n",
       "      <td>0.072501</td>\n",
       "      <td>0.410654</td>\n",
       "      <td>0.407858</td>\n",
       "      <td>0.130892</td>\n",
       "      <td>0.499323</td>\n",
       "      <td>0.499660</td>\n",
       "      <td>0.086679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>1615.500000</td>\n",
       "      <td>4.050000e+04</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-25229.000000</td>\n",
       "      <td>-17912.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>189145.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.125000e+05</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>16524.000000</td>\n",
       "      <td>2.385000e+05</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>-19682.000000</td>\n",
       "      <td>-2760.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>278202.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.471500e+05</td>\n",
       "      <td>5.135310e+05</td>\n",
       "      <td>24903.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-15750.000000</td>\n",
       "      <td>-1213.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>367142.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.025000e+05</td>\n",
       "      <td>8.086500e+05</td>\n",
       "      <td>34596.000000</td>\n",
       "      <td>6.795000e+05</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-12413.000000</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>456255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>258025.500000</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>-7489.000000</td>\n",
       "      <td>365243.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_CURR         TARGET   CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "count  307511.000000  307511.000000  307511.000000      3.075110e+05   \n",
       "mean   278180.518577       0.080729       0.417052      1.687979e+05   \n",
       "std    102790.175348       0.272419       0.722121      2.371231e+05   \n",
       "min    100002.000000       0.000000       0.000000      2.565000e+04   \n",
       "25%    189145.500000       0.000000       0.000000      1.125000e+05   \n",
       "50%    278202.000000       0.000000       0.000000      1.471500e+05   \n",
       "75%    367142.500000       0.000000       1.000000      2.025000e+05   \n",
       "max    456255.000000       1.000000      19.000000      1.170000e+08   \n",
       "\n",
       "         AMT_CREDIT    AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "count  3.075110e+05  307499.000000     3.072330e+05   \n",
       "mean   5.990260e+05   27108.573909     5.383962e+05   \n",
       "std    4.024908e+05   14493.737315     3.694465e+05   \n",
       "min    4.500000e+04    1615.500000     4.050000e+04   \n",
       "25%    2.700000e+05   16524.000000     2.385000e+05   \n",
       "50%    5.135310e+05   24903.000000     4.500000e+05   \n",
       "75%    8.086500e+05   34596.000000     6.795000e+05   \n",
       "max    4.050000e+06  258025.500000     4.050000e+06   \n",
       "\n",
       "       REGION_POPULATION_RELATIVE     DAYS_BIRTH  DAYS_EMPLOYED  ...  \\\n",
       "count               307511.000000  307511.000000  307511.000000  ...   \n",
       "mean                     0.020868  -16036.995067   63815.045904  ...   \n",
       "std                      0.013831    4363.988632  141275.766519  ...   \n",
       "min                      0.000290  -25229.000000  -17912.000000  ...   \n",
       "25%                      0.010006  -19682.000000   -2760.000000  ...   \n",
       "50%                      0.018850  -15750.000000   -1213.000000  ...   \n",
       "75%                      0.028663  -12413.000000    -289.000000  ...   \n",
       "max                      0.072508   -7489.000000  365243.000000  ...   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Mixed  WALLSMATERIAL_MODE_Monolithic  \\\n",
       "count             307511.000000                  307511.000000   \n",
       "mean                   0.007466                       0.005785   \n",
       "std                    0.086085                       0.075840   \n",
       "min                    0.000000                       0.000000   \n",
       "25%                    0.000000                       0.000000   \n",
       "50%                    0.000000                       0.000000   \n",
       "75%                    0.000000                       0.000000   \n",
       "max                    1.000000                       1.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_NaN  WALLSMATERIAL_MODE_Others  \\\n",
       "count           307511.000000              307511.000000   \n",
       "mean                 0.508408                   0.005284   \n",
       "std                  0.499930                   0.072501   \n",
       "min                  0.000000                   0.000000   \n",
       "25%                  0.000000                   0.000000   \n",
       "50%                  1.000000                   0.000000   \n",
       "75%                  1.000000                   0.000000   \n",
       "max                  1.000000                   1.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "count             307511.000000                    307511.000000   \n",
       "mean                   0.214757                         0.210773   \n",
       "std                    0.410654                         0.407858   \n",
       "min                    0.000000                         0.000000   \n",
       "25%                    0.000000                         0.000000   \n",
       "50%                    0.000000                         0.000000   \n",
       "75%                    0.000000                         0.000000   \n",
       "max                    1.000000                         1.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_NaN  \\\n",
       "count              307511.000000            307511.000000   \n",
       "mean                    0.017437                 0.473983   \n",
       "std                     0.130892                 0.499323   \n",
       "min                     0.000000                 0.000000   \n",
       "25%                     0.000000                 0.000000   \n",
       "50%                     0.000000                 0.000000   \n",
       "75%                     0.000000                 1.000000   \n",
       "max                     1.000000                 1.000000   \n",
       "\n",
       "       EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \n",
       "count           307511.000000            307511.000000  \n",
       "mean                 0.518446                 0.007570  \n",
       "std                  0.499660                 0.086679  \n",
       "min                  0.000000                 0.000000  \n",
       "25%                  0.000000                 0.000000  \n",
       "50%                  1.000000                 0.000000  \n",
       "75%                  1.000000                 0.000000  \n",
       "max                  1.000000                 1.000000  \n",
       "\n",
       "[8 rows x 426 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec des valeurs infinies :\n",
      "PREV_APP_CREDIT_PERC_MAX      PREV_APP_CREDIT_PERC_MAX\n",
      "PREV_APP_CREDIT_PERC_MEAN    PREV_APP_CREDIT_PERC_MEAN\n",
      "INSTAL_PAYMENT_PERC_MEAN      INSTAL_PAYMENT_PERC_MEAN\n",
      "INSTAL_PAYMENT_PERC_SUM        INSTAL_PAYMENT_PERC_SUM\n",
      "dtype: object\n",
      "\n",
      "Indices des lignes avec des valeurs infinies :\n",
      "[5687, 60477, 79077, 89018, 98509, 126768, 128791, 140426, 152087, 167136, 199103, 201086, 236164, 238381, 272829, 277962, 287300, 292852, 305373]\n",
      "\n",
      "Reste-t-il des valeurs infinies ?\n",
      "False\n",
      "\n",
      "Reste-t-il des valeurs infinies après remplacement ?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Sélectionner uniquement les colonnes numériques\n",
    "colonnes_numeriques = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Identifier les colonnes contenant des valeurs infinies\n",
    "colonnes_infinies = colonnes_numeriques.columns.to_series()[np.isinf(colonnes_numeriques).any()]\n",
    "\n",
    "# Affichage des colonnes avec des valeurs infinies\n",
    "print(\"Colonnes avec des valeurs infinies :\")\n",
    "print(colonnes_infinies)\n",
    "\n",
    "# Identifier les lignes contenant des valeurs infinies\n",
    "lignes_avec_infinis = df.index[np.isinf(colonnes_numeriques).any(axis=1)]\n",
    "\n",
    "# Affichage des indices des lignes contenant des valeurs infinies\n",
    "print(\"\\nIndices des lignes avec des valeurs infinies :\")\n",
    "print(lignes_avec_infinis.tolist())\n",
    "\n",
    "# Suppression des lignes contenant des valeurs infinies\n",
    "df.drop(lignes_avec_infinis, inplace=True)\n",
    "\n",
    "# Sélection des colonnes numériques après la suppression des lignes\n",
    "colonnes_numeriques = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Vérification\n",
    "print(\"\\nReste-t-il des valeurs infinies ?\")\n",
    "reste_infinis = np.isinf(colonnes_numeriques).any().any()\n",
    "print(reste_infinis)\n",
    "\n",
    "# Si des valeurs infinies restent, les remplacer par NaN\n",
    "if reste_infinis:\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    print(\"\\nLes valeurs infinies ont été remplacées par NaN.\")\n",
    "\n",
    "# Vérification\n",
    "reste_infinis = np.isinf(colonnes_numeriques).any().any()\n",
    "print(\"\\nReste-t-il des valeurs infinies après remplacement ?\")\n",
    "print(reste_infinis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle XGBoost...\n",
      "Meilleurs paramètres pour XGBoost: {'max_depth': 3, 'n_estimators': 100}\n",
      "Score F1 moyen sur le jeu de validation: 0.286\n",
      "Meilleur seuil pour minimiser le coût métier avec XGBoost: 0.4747474747474748\n",
      "AUC-ROC pour le modèle XGBoost: 0.750\n",
      "Rapport de classification avec le meilleur seuil pour XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.77      0.85      5663\n",
      "         1.0       0.18      0.60      0.28       486\n",
      "\n",
      "    accuracy                           0.76      6149\n",
      "   macro avg       0.57      0.69      0.57      6149\n",
      "weighted avg       0.90      0.76      0.81      6149\n",
      "\n",
      "Matrice de confusion avec le meilleur seuil pour XGBoost:\n",
      "[[4357 1306]\n",
      " [ 194  292]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adresse de MLflow\n",
    "mlflow_url = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Coût d'un faux positif et d'un faux négatif\n",
    "cost_fp = 1  \n",
    "cost_fn = 10  \n",
    "\n",
    "# Conserver la colonne d'identifiant unique\n",
    "id_column = 'SK_ID_CURR'\n",
    "df_id = df[[id_column]]  # Conserver les identifiants\n",
    "\n",
    "# Encodage des variables catégorielles avec OrdinalEncoder (hors colonne d'identifiant unique)\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df_encoded = pd.DataFrame(ordinal_encoder.fit_transform(df.drop(columns=[id_column])), columns=df.drop(columns=[id_column]).columns)\n",
    "\n",
    "# Vérification des colonnes non numériques\n",
    "non_numeric_cols = df_encoded.select_dtypes(exclude=[np.number]).columns\n",
    "df_encoded.drop(columns=non_numeric_cols, inplace=True)\n",
    "\n",
    "# Gestion des valeurs manquantes avec SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(df_encoded.drop(columns=['TARGET'])), columns=df_encoded.drop(columns=['TARGET']).columns)\n",
    "\n",
    "# Enregistrer X dans un fichier CSV pour l'utilisation dans l'API Flask\n",
    "X_to_save = X.copy()\n",
    "X_to_save['SK_ID_CURR'] = df_id['SK_ID_CURR'].values\n",
    "# Utilisation de la méthode reindex pour réorganiser les colonnes\n",
    "columns = ['SK_ID_CURR'] + [col for col in X_to_save.columns if col != 'SK_ID_CURR']\n",
    "X_to_save = X_to_save[columns]\n",
    "# Enregistrez le DataFrame dans un fichier CSV\n",
    "X_to_save.to_csv('X_predictionV0.csv', index=False)\n",
    "\n",
    "# Séparation des caractéristiques et la cible\n",
    "y = df_encoded['TARGET']\n",
    "\n",
    "# Séparation des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_to_save, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définir le modèle XGBoost avec ses paramètres\n",
    "model = XGBClassifier(scale_pos_weight=10, random_state=42)  \n",
    "params = {'n_estimators': [50, 100], 'max_depth': [3, 6, 9]}  \n",
    "\n",
    "# Configurer l'expérience MLflow\n",
    "mlflow.set_tracking_uri(mlflow_url)\n",
    "mlflow.set_experiment(\"Credit Scoring Experiment\")\n",
    "\n",
    "# Échantillonner les données\n",
    "sample_size = 0.1 \n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=(1 - sample_size), random_state=42)\n",
    "X_test_sample, _, y_test_sample, _ = train_test_split(X_test, y_test, test_size=(1 - sample_size), random_state=42)\n",
    "\n",
    "# Entraînement du modèle XGBoost obtention des meilleurs paramètres\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    print(\"Entraînement du modèle XGBoost...\")\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='f1', cv=3)\n",
    "    grid_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "    # Loguer les paramètres dans MLflow\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Affichage des meilleurs paramètres et le score F1\n",
    "    print(f\"Meilleurs paramètres pour XGBoost: {grid_search.best_params_}\")\n",
    "    print(f\"Score F1 moyen sur le jeu de validation: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # Utilisation du meilleur modèle pour les prédictions\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_prob = best_model.predict_proba(X_test_sample)[:, 1]\n",
    "\n",
    "    # Évaluation du modèle avec le meilleur seuil pour minimiser le coût métier\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    costs = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded = (y_prob > threshold).astype(int)\n",
    "        fp = np.sum((y_pred_thresholded == 1) & (y_test_sample == 0)) * cost_fp\n",
    "        fn = np.sum((y_pred_thresholded == 0) & (y_test_sample == 1)) * cost_fn\n",
    "        total_cost = fp + fn\n",
    "        costs.append(total_cost)\n",
    "\n",
    "    best_threshold = thresholds[np.argmin(costs)]\n",
    "    print(f\"Meilleur seuil pour minimiser le coût métier avec XGBoost: {best_threshold}\")\n",
    "\n",
    "    y_pred_best_threshold = (y_prob > best_threshold).astype(int)\n",
    "\n",
    "    # Calcul du score AUC-ROC\n",
    "    auc_roc = roc_auc_score(y_test_sample, y_prob)\n",
    "    print(f\"AUC-ROC pour le modèle XGBoost: {auc_roc:.3f}\")\n",
    "\n",
    "    # Affichage du rapport de classification et de la matrice de confusion\n",
    "    classification_report_str = classification_report(y_test_sample, y_pred_best_threshold)\n",
    "    confusion_matrix_str = confusion_matrix(y_test_sample, y_pred_best_threshold)\n",
    "\n",
    "    print(f\"Rapport de classification avec le meilleur seuil pour XGBoost:\")\n",
    "    print(classification_report_str)\n",
    "\n",
    "    print(f\"Matrice de confusion avec le meilleur seuil pour XGBoost:\")\n",
    "    print(confusion_matrix_str)\n",
    "    print()\n",
    "\n",
    "    # Loguer les métriques et les résultats dans MLflow\n",
    "    mlflow.log_metric(\"best_score_f1\", grid_search.best_score_)\n",
    "    mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "    mlflow.log_metric(\"auc_roc\", auc_roc)  # Loguer l'AUC-ROC\n",
    "    mlflow.log_text(classification_report_str, \"classification_report.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_str), \"confusion_matrix.txt\")\n",
    "\n",
    "    # Loguer le modèle\n",
    "    model_path = 'model/xgboost_model.pkl'\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "    # Sauvegarder le modèle dans un fichier .pkl\n",
    "    joblib.dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant avec une validation croisé plus poussée : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres pour XGBoost: {'subsample': 0.7, 'reg_lambda': 3, 'reg_alpha': 0, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.2, 'colsample_bytree': 0.7}\n",
      "Score F1 moyen sur le jeu de validation: 0.120\n",
      "Meilleur seuil pour minimiser le coût métier avec XGBoost: 0.08080808080808081\n",
      "AUC-ROC pour le modèle XGBoost: 0.738\n",
      "Rapport de classification avec le meilleur seuil pour XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.73      0.83      5663\n",
      "         1.0       0.17      0.63      0.27       486\n",
      "\n",
      "    accuracy                           0.72      6149\n",
      "   macro avg       0.56      0.68      0.55      6149\n",
      "weighted avg       0.90      0.72      0.79      6149\n",
      "\n",
      "Matrice de confusion avec le meilleur seuil pour XGBoost:\n",
      "[[4146 1517]\n",
      " [ 180  306]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/xgboost_model_optimized.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir la grille de paramètres plus ciblée\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'reg_alpha': [0, 0.01],\n",
    "    'reg_lambda': [1, 3]\n",
    "}\n",
    "\n",
    "# Entraînement du modèle XGBoost avec RandomizedSearchCV\n",
    "grid_search = RandomizedSearchCV(estimator=model, param_distributions=params, scoring='f1', cv=3, n_iter=30, random_state=42)\n",
    "grid_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Loguer les meilleurs paramètres et score\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Meilleurs paramètres pour XGBoost: {grid_search.best_params_}\")\n",
    "print(f\"Score F1 moyen sur le jeu de validation: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_prob = best_model.predict_proba(X_test_sample)[:, 1]\n",
    "y_pred = best_model.predict(X_test_sample)\n",
    "\n",
    "# Calcul du meilleur seuil pour minimiser le coût métier\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "costs = []\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresholded = (y_prob > threshold).astype(int)\n",
    "    fp = np.sum((y_pred_thresholded == 1) & (y_test_sample == 0)) * cost_fp\n",
    "    fn = np.sum((y_pred_thresholded == 0) & (y_test_sample == 1)) * cost_fn\n",
    "    total_cost = fp + fn\n",
    "    costs.append(total_cost)\n",
    "\n",
    "best_threshold = thresholds[np.argmin(costs)]\n",
    "print(f\"Meilleur seuil pour minimiser le coût métier avec XGBoost: {best_threshold}\")\n",
    "\n",
    "y_pred_best_threshold = (y_prob > best_threshold).astype(int)\n",
    "\n",
    "# Calcul du score AUC-ROC\n",
    "auc_roc = roc_auc_score(y_test_sample, y_prob)\n",
    "print(f\"AUC-ROC pour le modèle XGBoost: {auc_roc:.3f}\")\n",
    "\n",
    "# Rapport de classification et matrice de confusion\n",
    "classification_report_str = classification_report(y_test_sample, y_pred_best_threshold)\n",
    "confusion_matrix_str = confusion_matrix(y_test_sample, y_pred_best_threshold)\n",
    "\n",
    "print(f\"Rapport de classification avec le meilleur seuil pour XGBoost:\")\n",
    "print(classification_report_str)\n",
    "\n",
    "print(f\"Matrice de confusion avec le meilleur seuil pour XGBoost:\")\n",
    "print(confusion_matrix_str)\n",
    "\n",
    "# Loguer les métriques et le modèle dans MLflow\n",
    "mlflow.log_metric(\"best_score_f1\", grid_search.best_score_)\n",
    "mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "mlflow.log_metric(\"auc_roc\", auc_roc)\n",
    "mlflow.log_text(classification_report_str, \"classification_report.txt\")\n",
    "mlflow.log_text(str(confusion_matrix_str), \"confusion_matrix.txt\")\n",
    "\n",
    "model_path = 'model/xgboost_model_optimized.pkl'\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "# Sauvegarder le modèle dans un fichier .pkl\n",
    "joblib.dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle XGBoost avec validation croisée...\n",
      "Meilleurs paramètres pour XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Score F1 moyen sur le jeu de validation: 0.066\n",
      "Meilleur seuil pour minimiser le coût métier avec XGBoost: 0.11111111111111112\n",
      "Rapport de classification avec le meilleur seuil pour XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87      5663\n",
      "         1.0       0.20      0.59      0.30       486\n",
      "\n",
      "    accuracy                           0.78      6149\n",
      "   macro avg       0.58      0.70      0.59      6149\n",
      "weighted avg       0.90      0.78      0.83      6149\n",
      "\n",
      "Matrice de confusion avec le meilleur seuil pour XGBoost:\n",
      "[[4540 1123]\n",
      " [ 200  286]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adresse de MLflow\n",
    "mlflow_url = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Configurer l'expérience MLflow\n",
    "mlflow.set_tracking_uri(mlflow_url)\n",
    "mlflow.set_experiment(\"Credit Scoring Experiment\")\n",
    "\n",
    "# Définition du modèle XGBoost et des paramètres à optimiser\n",
    "model = XGBClassifier()\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200, 250],\n",
    "    'max_depth': [3, 6, 9, 11],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Entraînement du modèle XGBoost avec validation croisée\n",
    "with mlflow.start_run(run_name=\"XGBoost with Cross-Validation\"):\n",
    "    print(\"Entraînement du modèle XGBoost avec validation croisée...\")\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='f1', cv=3)\n",
    "    \n",
    "    # Entraînement avec GridSearchCV et suivi MLflow\n",
    "    grid_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "    # Loguer les meilleurs paramètres dans MLflow\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Affichage des meilleurs paramètres et le score F1\n",
    "    print(f\"Meilleurs paramètres pour XGBoost: {grid_search.best_params_}\")\n",
    "    print(f\"Score F1 moyen sur le jeu de validation: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # Utilisation du meilleur modèle pour les prédictions\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Prédictions avec validation croisée pour obtenir les prédictions stables\n",
    "    y_pred = cross_val_predict(best_model, X_test_sample, y_test_sample, cv=3)\n",
    "\n",
    "    # Évaluation du modèle avec le meilleur seuil pour minimiser le coût métier\n",
    "    y_prob = best_model.predict_proba(X_test_sample)[:, 1]\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    costs = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded = (y_prob > threshold).astype(int)\n",
    "        fp = np.sum((y_pred_thresholded == 1) & (y_test_sample == 0)) * cost_fp\n",
    "        fn = np.sum((y_pred_thresholded == 0) & (y_test_sample == 1)) * cost_fn\n",
    "        total_cost = fp + fn\n",
    "        costs.append(total_cost)\n",
    "\n",
    "    best_threshold = thresholds[np.argmin(costs)]\n",
    "    print(f\"Meilleur seuil pour minimiser le coût métier avec XGBoost: {best_threshold}\")\n",
    "\n",
    "    y_pred_best_threshold = (y_prob > best_threshold).astype(int)\n",
    "\n",
    "    # Affichage du rapport de classification et de la matrice de confusion\n",
    "    classification_report_str = classification_report(y_test_sample, y_pred_best_threshold)\n",
    "    confusion_matrix_str = confusion_matrix(y_test_sample, y_pred_best_threshold)\n",
    "\n",
    "    print(f\"Rapport de classification avec le meilleur seuil pour XGBoost:\")\n",
    "    print(classification_report_str)\n",
    "\n",
    "    print(f\"Matrice de confusion avec le meilleur seuil pour XGBoost:\")\n",
    "    print(confusion_matrix_str)\n",
    "    print()\n",
    "\n",
    "    # Loguer les métriques et les résultats dans MLflow\n",
    "    mlflow.log_metric(\"best_score_f1\", grid_search.best_score_)\n",
    "    mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "    mlflow.log_text(classification_report_str, \"classification_report.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_str), \"confusion_matrix.txt\")\n",
    "\n",
    "    # Loguer le modèle\n",
    "    model_path = 'model/xgboost_model_cv.pkl'\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "    # Sauvegarder le modèle dans un fichier .pkl\n",
    "    joblib.dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En résumé, l'utilisation de la validation croisée a permis d'obtenir des paramètres optimisés pour le modèle XGBoost. Les résultats montrent une légère amélioration du rappel et du score F1 pour la classe 1 (classe minoritaire), ainsi qu'une précision globale et une matrice de confusion plus équilibrées. La validation croisée semble donc offrir une meilleure généralisation des performances du modèle, notamment pour la classe minoritaire, ce qui est crucial pour le problème de scoring de crédit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des caractéristiques importantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meilleur modèle sélectionné après l'entraînement et l'optimisation\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Récupérer le nom des colonnes d'entraînement\n",
    "feature_names = X_train_sample.columns\n",
    "\n",
    "# Créer un DataFrame pour mieux visualiser les importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Trier par ordre décroissant d'importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Afficher les 10 caractéristiques les plus importantes\n",
    "top_10_features = feature_importance_df.head(12)\n",
    "print(\"Top 10 des caractéristiques importantes :\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10_features['Feature'], top_10_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 10 des Caractéristiques Importantes')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici la description de chaque caractéristique parmi les plus importantes :\n",
    "\n",
    "EXT_SOURCE_3\n",
    "\n",
    "Description : C'est une des sources de notation de crédit externes, souvent provenant de bureaux de crédit ou d'autres agences d'évaluation. La valeur indique une estimation de la probabilité de défaut de l'emprunteur par une source externe. La source spécifique peut varier mais généralement, les valeurs plus élevées indiquent un risque de crédit plus faible.\n",
    "\n",
    "EXT_SOURCE_2\n",
    "Description : Similaire à EXT_SOURCE_3, c'est une autre source externe de notation de crédit. Elle fournit une évaluation externe de la probabilité de défaut de l'emprunteur. Comme pour EXT_SOURCE_3, les valeurs plus élevées indiquent un risque de crédit plus faible.\n",
    "\n",
    "FLAG_EMP_PHONE\n",
    "Description : Indique si l'emprunteur a fourni un numéro de téléphone professionnel. C'est une variable binaire où 1 signifie que l'emprunteur a fourni un numéro de téléphone professionnel et 0 signifie qu'il ne l'a pas fait.\n",
    "\n",
    "CC_CNT_DRAWINGS_CURRENT_MEAN\n",
    "Description : C'est la moyenne des dessins (retraits) courants sur la carte de crédit de l'emprunteur. Cela donne une idée de la fréquence et du montant des retraits effectués par l'emprunteur sur sa carte de crédit.\n",
    "\n",
    "CC_AMT_RECEIVABLE_PRINCIPAL_MEAN\n",
    "Description : C'est la moyenne des montants recevables principaux (le principal restant dû) sur la carte de crédit de l'emprunteur. Cela indique combien l'emprunteur doit encore payer sur le principal de ses dettes de carte de crédit.\n",
    "\n",
    "NAME_EDUCATION_TYPE\n",
    "Description : C'est le niveau d'éducation de l'emprunteur. Les catégories peuvent inclure \"Secondaire / secondaire spécial\", \"Enseignement supérieur\", \"Enseignement professionnel\", etc. Ce type de donnée est généralement encodé numériquement pour être utilisé dans les modèles de machine learning.\n",
    "\n",
    "CC_MONTHS_BALANCE_SIZE\n",
    "Description : Cela représente la taille de l'historique des soldes mensuels des cartes de crédit de l'emprunteur. En d'autres termes, combien de mois de données de solde de carte de crédit sont disponibles pour l'emprunteur.\n",
    "\n",
    "CC_AMT_BALANCE_MEAN\n",
    "Description : C'est la moyenne des soldes des cartes de crédit de l'emprunteur. Cela donne une idée de combien l'emprunteur a en moyenne comme solde sur ses cartes de crédit.\n",
    "\n",
    "PREV_NAME_YIELD_GROUP_low_action_MEAN\n",
    "Description : Cela représente la moyenne des précédents groupes de rendement (yield groups) catégorisés comme \"low_action\". Ces groupes de rendement sont utilisés pour classer les précédents prêts de l'emprunteur en fonction de leur performance financière (par exemple, rendement élevé, rendement faible, etc.).\n",
    "\n",
    "PREV_DAYS_FIRST_DRAWING_MIN\n",
    "Description : C'est le nombre minimum de jours jusqu'au premier retrait sur les précédents prêts de l'emprunteur. Cela indique combien de jours se sont écoulés avant que l'emprunteur effectue le premier retrait sur ses précédents prêts.\n",
    "\n",
    "CC_CNT_DRAWINGS_CURRENT_MAX\n",
    "Type: float64\n",
    "Exemple de valeur: 0.005005\n",
    "Description: Valeur maximale du nombre de dessins actuels sur les cartes de crédit. Cette variable représente la valeur maximale observée pour le nombre de transactions de dessin sur les cartes de crédit.\n",
    "\n",
    "BURO_CREDIT_ACTIVE_Closed_MEAN\n",
    "Type: float64\n",
    "Exemple de valeur: 0.004893\n",
    "Description: Moyenne de l'état des crédits passés où l'état est \"Fermé\". Cette variable représente la proportion moyenne des crédits passés qui sont maintenant fermés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "chemin_dossier = \"C:/Users/paulm/Documents/Projet 7/Projet7withCSV/data/\" \n",
    "data = pd.read_csv(os.path.join(chemin_dossier, 'processed_data_encoded.csv'))\n",
    "\n",
    "# Sélectionner les colonnes importantes\n",
    "important_features = [\n",
    "    'EXT_SOURCE_3',\n",
    "    'EXT_SOURCE_2',\n",
    "    'FLAG_EMP_PHONE',\n",
    "    'CC_CNT_DRAWINGS_CURRENT_MEAN',\n",
    "    'CC_AMT_RECEIVABLE_PRINCIPAL_MEAN',\n",
    "    'NAME_EDUCATION_TYPE',\n",
    "    'CC_MONTHS_BALANCE_SIZE',\n",
    "    'CC_AMT_BALANCE_MEAN',\n",
    "    'PREV_NAME_YIELD_GROUP_low_action_MEAN',\n",
    "    'PREV_DAYS_FIRST_DRAWING_MIN'\n",
    "]\n",
    "\n",
    "# Filtrer les données pour n'afficher que les colonnes importantes\n",
    "important_data = data[important_features]\n",
    "\n",
    "# Afficher un aperçu des données\n",
    "print(important_data.head())\n",
    "\n",
    "# Afficher des statistiques descriptives pour chaque colonne\n",
    "print(important_data.describe())\n",
    "\n",
    "# Afficher les types de données pour chaque colonne\n",
    "print(important_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation et tests de l'influence des caractéristiques importantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le modèle XGBoost\n",
    "model = XGBClassifier(scale_pos_weight=10, random_state=42)\n",
    "\n",
    "# Entraînement du modèle avec toutes les caractéristiques\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Créer un DataFrame pour l'importance des caractéristiques\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "\n",
    "# Trier les caractéristiques par importance\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Sélectionner les 50 caractéristiques les plus importantes\n",
    "num_features_to_keep = 50\n",
    "important_features = feature_importances.head(num_features_to_keep)['feature']\n",
    "\n",
    "# Réduire X_train et X_test aux caractéristiques sélectionnées\n",
    "X_train_reduced = X_train[important_features]\n",
    "X_test_reduced = X_test[important_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration de MLflow et de la validation croisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la validation croisée\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Définir les paramètres de la recherche de grille\n",
    "params = {'n_estimators': [50, 100], 'max_depth': [3, 6, 9]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement et validation du modèle XGBoost avec les caractéristiques réduites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le modèle XGBoost avec les caractéristiques réduites\n",
    "model_reduced = XGBClassifier(scale_pos_weight=10, random_state=42)\n",
    "\n",
    "# Effectuer la recherche de grille avec les données réduites\n",
    "grid_search_reduced = GridSearchCV(estimator=model_reduced, param_grid=params, scoring='f1', cv=cv)\n",
    "grid_search_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Loguer les paramètres dans MLflow\n",
    "with mlflow.start_run(run_name=\"XGBoost Reduced Features\"):\n",
    "    print(\"Entraînement du modèle XGBoost avec caractéristiques réduites...\")\n",
    "\n",
    "    # Loguer les paramètres\n",
    "    mlflow.log_params(grid_search_reduced.best_params_)\n",
    "\n",
    "    # Affichage des meilleurs paramètres et le score F1\n",
    "    print(f\"Meilleurs paramètres pour XGBoost avec caractéristiques réduites: {grid_search_reduced.best_params_}\")\n",
    "    print(f\"Score F1 moyen sur le jeu de validation: {grid_search_reduced.best_score_:.3f}\")\n",
    "\n",
    "    # Utilisation du meilleur modèle pour les prédictions\n",
    "    best_model_reduced = grid_search_reduced.best_estimator_\n",
    "    y_pred_reduced = best_model_reduced.predict(X_test_reduced)\n",
    "\n",
    "    # Évaluation du modèle avec le meilleur seuil pour minimiser le coût métier\n",
    "    y_prob_reduced = best_model_reduced.predict_proba(X_test_reduced)[:, 1]\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    costs = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded_reduced = (y_prob_reduced > threshold).astype(int)\n",
    "        fp = np.sum((y_pred_thresholded_reduced == 1) & (y_test == 0)) * cost_fp\n",
    "        fn = np.sum((y_pred_thresholded_reduced == 0) & (y_test == 1)) * cost_fn\n",
    "        total_cost = fp + fn\n",
    "        costs.append(total_cost)\n",
    "\n",
    "    best_threshold_reduced = thresholds[np.argmin(costs)]\n",
    "    print(f\"Meilleur seuil pour minimiser le coût métier avec caractéristiques réduites: {best_threshold_reduced}\")\n",
    "\n",
    "    y_pred_best_threshold_reduced = (y_prob_reduced > best_threshold_reduced).astype(int)\n",
    "\n",
    "    # Affichage du rapport de classification et de la matrice de confusion\n",
    "    classification_report_str_reduced = classification_report(y_test, y_pred_best_threshold_reduced)\n",
    "    confusion_matrix_str_reduced = confusion_matrix(y_test, y_pred_best_threshold_reduced)\n",
    "\n",
    "    print(f\"Rapport de classification avec le meilleur seuil pour XGBoost avec caractéristiques réduites:\")\n",
    "    print(classification_report_str_reduced)\n",
    "\n",
    "    print(f\"Matrice de confusion avec le meilleur seuil pour XGBoost avec caractéristiques réduites:\")\n",
    "    print(confusion_matrix_str_reduced)\n",
    "    print()\n",
    "\n",
    "    # Loguer les métriques et les résultats dans MLflow\n",
    "    mlflow.log_metric(\"best_score_f1_reduced\", grid_search_reduced.best_score_)\n",
    "    mlflow.log_metric(\"best_threshold_reduced\", best_threshold_reduced)\n",
    "    mlflow.log_text(classification_report_str_reduced, \"classification_report_reduced.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_str_reduced), \"confusion_matrix_reduced.txt\")\n",
    "\n",
    "    # Loguer le modèle\n",
    "    model_path_reduced = 'model/xgboost_model_reduced.pkl'\n",
    "    os.makedirs(os.path.dirname(model_path_reduced), exist_ok=True)\n",
    "    mlflow.sklearn.log_model(best_model_reduced, \"model_reduced\")\n",
    "\n",
    "    # Sauvegarder le modèle dans un fichier .pkl\n",
    "    joblib.dump(best_model_reduced, model_path_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusion, mon approche de réduction de caractéristiques semble ne pas être bénéfique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-6.5.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
