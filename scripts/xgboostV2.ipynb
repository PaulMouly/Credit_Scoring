{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import mlflow\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "chemin_dossier = \"C:/Users/paulm/Documents/Projet 7/Projet7withCSV/data/\" \n",
    "df = pd.read_csv(os.path.join(chemin_dossier, 'processed_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes avec trop de valeurs uniques\n",
    "colonnes_a_supprimer = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "df.drop(columns=colonnes_a_supprimer, inplace=True)\n",
    "\n",
    "# Sélectionner uniquement les colonnes numériques\n",
    "colonnes_numeriques = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Identifier les colonnes contenant des valeurs infinies\n",
    "colonnes_infinies = colonnes_numeriques.columns.to_series()[np.isinf(colonnes_numeriques).any()]\n",
    "# Identifier les lignes contenant des valeurs infinies\n",
    "lignes_avec_infinis = df.index[np.isinf(colonnes_numeriques).any(axis=1)]\n",
    "# Suppression des lignes contenant des valeurs infinies\n",
    "df.drop(lignes_avec_infinis, inplace=True)\n",
    "\n",
    "# Encodage des variables catégorielles avec OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df_encoded = pd.DataFrame(ordinal_encoder.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Créer un imputeur avec la stratégie de votre choix (mean, median, most_frequent)\n",
    "imputer = SimpleImputer(strategy='mean') \n",
    "\n",
    "# Appliquer l'imputation sur les données numériques\n",
    "colonnes_numeriques = df_encoded.select_dtypes(include=[np.number])\n",
    "df_encoded[colonnes_numeriques.columns] = imputer.fit_transform(colonnes_numeriques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              0.0\n",
      "1              1.0\n",
      "2              2.0\n",
      "3              3.0\n",
      "4              4.0\n",
      "            ...   \n",
      "307487    307487.0\n",
      "307488    307488.0\n",
      "307489    307489.0\n",
      "307490    307490.0\n",
      "307491    307491.0\n",
      "Name: SK_ID_CURR, Length: 307492, dtype: float64\n",
      "0         100002\n",
      "1         100003\n",
      "2         100004\n",
      "3         100006\n",
      "4         100007\n",
      "           ...  \n",
      "307506    456251\n",
      "307507    456252\n",
      "307508    456253\n",
      "307509    456254\n",
      "307510    456255\n",
      "Name: SK_ID_CURR, Length: 307492, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded['SK_ID_CURR'])\n",
    "print(df['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96     56609\n",
      "         1.0       0.46      0.07      0.12      4890\n",
      "\n",
      "    accuracy                           0.92     61499\n",
      "   macro avg       0.69      0.53      0.54     61499\n",
      "weighted avg       0.89      0.92      0.89     61499\n",
      "\n",
      "Matrice de confusion :\n",
      "[[56220   389]\n",
      " [ 4561   329]]\n",
      "Meilleur seuil pour minimiser le coût métier : 0.08080808080808081\n",
      "Rapport de classification avec le meilleur seuil :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.74      0.83     56609\n",
      "         1.0       0.18      0.66      0.28      4890\n",
      "\n",
      "    accuracy                           0.73     61499\n",
      "   macro avg       0.57      0.70      0.56     61499\n",
      "weighted avg       0.90      0.73      0.79     61499\n",
      "\n",
      "Matrice de confusion avec le meilleur seuil :\n",
      "[[41655 14954]\n",
      " [ 1661  3229]]\n",
      "Modèle enregistré à : model/xgboost_model.pkl\n"
     ]
    }
   ],
   "source": [
    "X = df_encoded.drop(columns=['TARGET'])  \n",
    "y = df_encoded['TARGET']\n",
    "\n",
    "# Définir l'URL de suivi de MLflow\n",
    "mlflow_url = \"http://127.0.0.1:5000\"\n",
    "mlflow.set_tracking_uri(mlflow_url)\n",
    "\n",
    "# Configurer l'expérience MLflow\n",
    "mlflow.set_experiment(\"Credit Scoring Experiment\")\n",
    "\n",
    "# Fractionner les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définir votre modèle XGBoost\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Entraîner votre modèle XGBoost\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Enregistrer le modèle dans un fichier .pkl à l'aide de joblib\n",
    "model_path = 'model/xgboost_model.pkl'\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Utiliser MLflow pour suivre votre modèle\n",
    "with mlflow.start_run(run_name=\"XGBoost Model\"):\n",
    "    # Loguer les paramètres du modèle\n",
    "    mlflow.log_params({\n",
    "        'n_estimators': model.get_params()['n_estimators'],\n",
    "        'max_depth': model.get_params()['max_depth'],\n",
    "        'learning_rate': model.get_params()['learning_rate']\n",
    "    })\n",
    "\n",
    "    # Faire des prédictions sur l'ensemble de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher le rapport de classification et la matrice de confusion\n",
    "    classification_report_str = classification_report(y_test, y_pred)\n",
    "    confusion_matrix_str = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Rapport de classification :\")\n",
    "    print(classification_report_str)\n",
    "\n",
    "    print(\"Matrice de confusion :\")\n",
    "    print(confusion_matrix_str)\n",
    "\n",
    "    # Loguer les métriques et les résultats dans MLflow\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "    mlflow.log_text(classification_report_str, \"classification_report.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_str), \"confusion_matrix.txt\")\n",
    "\n",
    "    # Évaluation du modèle avec le meilleur seuil pour minimiser le coût métier\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    costs = []\n",
    "    cost_fp = 1\n",
    "    cost_fn = 10\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded = (y_prob > threshold).astype(int)\n",
    "        fp = np.sum((y_pred_thresholded == 1) & (y_test == 0)) * cost_fp\n",
    "        fn = np.sum((y_pred_thresholded == 0) & (y_test == 1)) * cost_fn\n",
    "        total_cost = fp + fn\n",
    "        costs.append(total_cost)\n",
    "\n",
    "    best_threshold = thresholds[np.argmin(costs)]\n",
    "    print(f\"Meilleur seuil pour minimiser le coût métier : {best_threshold}\")\n",
    "\n",
    "    y_pred_best_threshold = (y_prob > best_threshold).astype(int)\n",
    "\n",
    "    # Affichage du rapport de classification et de la matrice de confusion avec le meilleur seuil\n",
    "    classification_report_str_best = classification_report(y_test, y_pred_best_threshold)\n",
    "    confusion_matrix_str_best = confusion_matrix(y_test, y_pred_best_threshold)\n",
    "\n",
    "    print(\"Rapport de classification avec le meilleur seuil :\")\n",
    "    print(classification_report_str_best)\n",
    "\n",
    "    print(\"Matrice de confusion avec le meilleur seuil :\")\n",
    "    print(confusion_matrix_str_best)\n",
    "\n",
    "    # Loguer les métriques et les résultats avec le meilleur seuil dans MLflow\n",
    "    mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "    mlflow.log_text(classification_report_str_best, \"classification_report_best_threshold.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_str_best), \"confusion_matrix_best_threshold.txt\")\n",
    "\n",
    "    # Loguer le modèle dans MLflow\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "# Afficher le chemin du modèle sauvegardé\n",
    "print(f\"Modèle enregistré à : {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparation des caractéristiques et de la cible, division en ensembles d'entraînement et de test :\n",
    "X = df_encoded.drop(columns=['TARGET'])\n",
    "y = df_encoded['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlflow_url = \"http://127.0.0.1:5000\"\n",
    "mlflow.set_tracking_uri(mlflow_url)\n",
    "mlflow.set_experiment(\"Credit Scoring Experiment\")\n",
    "\n",
    "model = XGBClassifier(scale_pos_weight=10, random_state=42)\n",
    "params = {'n_estimators': [50, 100], 'max_depth': [3, 6, 9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres pour XGBoost: {'max_depth': 6, 'n_estimators': 100}\n",
      "Score F1 moyen sur le jeu de validation: 0.302\n",
      "Meilleur seuil pour minimiser le coût métier avec XGBoost: 0.4141414141414142\n",
      "Rapport de classification avec le meilleur seuil pour XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.72      0.82     56609\n",
      "         1.0       0.17      0.67      0.27      4890\n",
      "\n",
      "    accuracy                           0.72     61499\n",
      "   macro avg       0.57      0.69      0.55     61499\n",
      "weighted avg       0.90      0.72      0.78     61499\n",
      "\n",
      "Matrice de confusion avec le meilleur seuil pour XGBoost:\n",
      "[[40812 15797]\n",
      " [ 1620  3270]]\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='f1', cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    print(f\"Meilleurs paramètres pour XGBoost: {grid_search.best_params_}\")\n",
    "    print(f\"Score F1 moyen sur le jeu de validation: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Évaluation du modèle avec le meilleur seuil pour minimiser le coût métier\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    costs = []\n",
    "    cost_fp = 1\n",
    "    cost_fn = 10\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded = (y_prob > threshold).astype(int)\n",
    "        fp = np.sum((y_pred_thresholded == 1) & (y_test == 0)) * cost_fp\n",
    "        fn = np.sum((y_pred_thresholded == 0) & (y_test == 1)) * cost_fn\n",
    "        total_cost = fp + fn\n",
    "        costs.append(total_cost)\n",
    "\n",
    "    best_threshold = thresholds[np.argmin(costs)]\n",
    "    print(f\"Meilleur seuil pour minimiser le coût métier avec XGBoost: {best_threshold}\")\n",
    "\n",
    "    y_pred_best_threshold = (y_prob > best_threshold).astype(int)\n",
    "\n",
    "    # Affichage du rapport de classification et de la matrice de confusion\n",
    "    classification_report_str = classification_report(y_test, y_pred_best_threshold)\n",
    "    confusion_matrix_str = confusion_matrix(y_test, y_pred_best_threshold)\n",
    "\n",
    "    print(f\"Rapport de classification avec le meilleur seuil pour XGBoost:\")\n",
    "    print(classification_report_str)\n",
    "\n",
    "    print(f\"Matrice de confusion avec le meilleur seuil pour XGBoost:\")\n",
    "    print(confusion_matrix_str)\n",
    "\n",
    "    mlflow.log_metric(\"best_score_f1\", grid_search.best_score_)\n",
    "    mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "    mlflow.log_text(classification_report_str, \"classification_report.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_str), \"confusion_matrix.txt\")\n",
    "\n",
    "    # Loguer le modèle\n",
    "    model_path = 'model/xgboost_model.pkl'\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    joblib.dump(best_model, model_path)\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle XGBoost avec validation croisée...\n",
      "Meilleurs paramètres pour XGBoost: {'max_depth': 6, 'n_estimators': 100}\n",
      "Score F1 moyen sur le jeu de validation: 0.303\n",
      "Score F1 sur le jeu de test avec XGBoost et validation croisée : 0.261\n",
      "Rapport de classification sur le jeu de test avec XGBoost et validation croisée :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.90      0.92     56609\n",
      "         1.0       0.22      0.32      0.26      4890\n",
      "\n",
      "    accuracy                           0.86     61499\n",
      "   macro avg       0.58      0.61      0.59     61499\n",
      "weighted avg       0.88      0.86      0.87     61499\n",
      "\n",
      "Matrice de confusion sur le jeu de test avec XGBoost et validation croisée :\n",
      "[[51179  5430]\n",
      " [ 3343  1547]]\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle avec GridSearchCV et validation croisée\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    print(\"Entraînement du modèle XGBoost avec validation croisée...\")\n",
    "\n",
    "    # Utilisation de KFold pour la validation croisée\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='f1', cv=kf)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    print(f\"Meilleurs paramètres pour XGBoost: {grid_search.best_params_}\")\n",
    "    print(f\"Score F1 moyen sur le jeu de validation: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # Évaluation du modèle avec les meilleures paramètres sur le jeu de test\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Prédiction avec validation croisée\n",
    "    y_pred_cv = cross_val_predict(best_model, X_test, y_test, cv=kf)\n",
    "\n",
    "    # Calcul des métriques sur les prédictions\n",
    "    f1_cv = f1_score(y_test, y_pred_cv)\n",
    "    classification_report_cv = classification_report(y_test, y_pred_cv)\n",
    "    confusion_matrix_cv = confusion_matrix(y_test, y_pred_cv)\n",
    "\n",
    "    print(f\"Score F1 sur le jeu de test avec XGBoost et validation croisée : {f1_cv:.3f}\")\n",
    "    print(f\"Rapport de classification sur le jeu de test avec XGBoost et validation croisée :\")\n",
    "    print(classification_report_cv)\n",
    "    print(f\"Matrice de confusion sur le jeu de test avec XGBoost et validation croisée :\")\n",
    "    print(confusion_matrix_cv)\n",
    "\n",
    "    mlflow.log_metric(\"f1_score_cv\", f1_cv)\n",
    "    mlflow.log_text(classification_report_cv, \"classification_report_cv.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_cv), \"confusion_matrix_cv.txt\")\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    model_path = 'model/xgboost_model_cv.pkl'\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    joblib.dump(best_model, model_path)\n",
    "    mlflow.sklearn.log_model(best_model, \"model_cv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
