{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne 'NAME_CONTRACT_TYPE' contient 2 valeurs uniques.\n",
      "Colonne 'CODE_GENDER' contient 3 valeurs uniques.\n",
      "Colonne 'FLAG_OWN_CAR' contient 2 valeurs uniques.\n",
      "Colonne 'FLAG_OWN_REALTY' contient 2 valeurs uniques.\n",
      "Colonne 'NAME_TYPE_SUITE' contient 7 valeurs uniques.\n",
      "Colonne 'NAME_INCOME_TYPE' contient 8 valeurs uniques.\n",
      "Colonne 'NAME_EDUCATION_TYPE' contient 5 valeurs uniques.\n",
      "Colonne 'NAME_FAMILY_STATUS' contient 6 valeurs uniques.\n",
      "Colonne 'NAME_HOUSING_TYPE' contient 6 valeurs uniques.\n",
      "Colonne 'OCCUPATION_TYPE' contient 18 valeurs uniques.\n",
      "Colonne 'WEEKDAY_APPR_PROCESS_START' contient 7 valeurs uniques.\n",
      "Colonne 'ORGANIZATION_TYPE' contient 58 valeurs uniques.\n",
      "Colonne 'FONDKAPREMONT_MODE' contient 4 valeurs uniques.\n",
      "Colonne 'HOUSETYPE_MODE' contient 3 valeurs uniques.\n",
      "Colonne 'WALLSMATERIAL_MODE' contient 7 valeurs uniques.\n",
      "Colonne 'EMERGENCYSTATE_MODE' contient 2 valeurs uniques.\n",
      "Colonnes avec des valeurs infinies :\n",
      "PREV_APP_CREDIT_PERC_MAX      PREV_APP_CREDIT_PERC_MAX\n",
      "PREV_APP_CREDIT_PERC_MEAN    PREV_APP_CREDIT_PERC_MEAN\n",
      "INSTAL_PAYMENT_PERC_MEAN      INSTAL_PAYMENT_PERC_MEAN\n",
      "INSTAL_PAYMENT_PERC_SUM        INSTAL_PAYMENT_PERC_SUM\n",
      "dtype: object\n",
      "\n",
      "Indices des lignes avec des valeurs infinies :\n",
      "[5687, 60477, 79077, 89018, 98509, 126768, 128791, 140426, 152087, 167136, 199103, 201086, 236164, 238381, 272829, 277962, 287300, 292852, 305373]\n",
      "\n",
      "Reste-t-il des valeurs infinies ?\n",
      "False\n",
      "\n",
      "Reste-t-il des valeurs infinies après remplacement ?\n",
      "False\n",
      "Entraînement du modèle XGBoost...\n",
      "Meilleurs paramètres pour XGBoost: {'max_depth': 3, 'n_estimators': 100}\n",
      "Score F1 moyen sur le jeu de validation: 0.289\n",
      "Meilleur seuil pour minimiser le coût métier avec XGBoost: 0.494949494949495\n",
      "Rapport de classification avec le meilleur seuil pour XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.79      0.87      5663\n",
      "         1.0       0.20      0.59      0.29       486\n",
      "\n",
      "    accuracy                           0.78      6149\n",
      "   macro avg       0.58      0.69      0.58      6149\n",
      "weighted avg       0.90      0.78      0.82      6149\n",
      "\n",
      "Matrice de confusion avec le meilleur seuil pour XGBoost:\n",
      "[[4491 1172]\n",
      " [ 200  286]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['preprocessing/preprocessing_pipeline.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Chargement des données\n",
    "chemin_dossier = \"C:/Users/paulm/Documents/Projet 7/Projet7withCSV/data/\"\n",
    "df = pd.read_csv(os.path.join(chemin_dossier, 'processed_data.csv'))\n",
    "\n",
    "# Sélection des colonnes catégorielles\n",
    "colonnes_categorielles = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Affichage du nombre de valeurs uniques dans chaque colonne catégorielle\n",
    "for col in colonnes_categorielles:\n",
    "    nb_valeurs_uniques = df[col].nunique()\n",
    "    print(f\"Colonne '{col}' contient {nb_valeurs_uniques} valeurs uniques.\")\n",
    "\n",
    "# Suppression des colonnes avec trop de valeurs uniques\n",
    "colonnes_a_supprimer = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "df.drop(columns=colonnes_a_supprimer, inplace=True)\n",
    "\n",
    "# Sélectionner uniquement les colonnes numériques\n",
    "colonnes_numeriques = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Identifier les colonnes contenant des valeurs infinies\n",
    "colonnes_infinies = colonnes_numeriques.columns.to_series()[np.isinf(colonnes_numeriques).any()]\n",
    "\n",
    "# Affichage des colonnes avec des valeurs infinies\n",
    "print(\"Colonnes avec des valeurs infinies :\")\n",
    "print(colonnes_infinies)\n",
    "\n",
    "# Identifier les lignes contenant des valeurs infinies\n",
    "lignes_avec_infinis = df.index[np.isinf(colonnes_numeriques).any(axis=1)]\n",
    "\n",
    "# Affichage des indices des lignes contenant des valeurs infinies\n",
    "print(\"\\nIndices des lignes avec des valeurs infinies :\")\n",
    "print(lignes_avec_infinis.tolist())\n",
    "\n",
    "# Suppression des lignes contenant des valeurs infinies\n",
    "df.drop(lignes_avec_infinis, inplace=True)\n",
    "\n",
    "# Sélection des colonnes numériques après la suppression des lignes\n",
    "colonnes_numeriques = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Vérification\n",
    "print(\"\\nReste-t-il des valeurs infinies ?\")\n",
    "reste_infinis = np.isinf(colonnes_numeriques).any().any()\n",
    "print(reste_infinis)\n",
    "\n",
    "# Si des valeurs infinies restent, les remplacer par NaN\n",
    "if reste_infinis:\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    print(\"\\nLes valeurs infinies ont été remplacées par NaN.\")\n",
    "\n",
    "# Vérification\n",
    "reste_infinis = np.isinf(colonnes_numeriques).any().any()\n",
    "print(\"\\nReste-t-il des valeurs infinies après remplacement ?\")\n",
    "print(reste_infinis)\n",
    "\n",
    "# Adresse de MLflow\n",
    "mlflow_url = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Coût d'un faux positif et d'un faux négatif\n",
    "cost_fp = 1  \n",
    "cost_fn = 10  \n",
    "\n",
    "# Encodage des variables catégorielles avec OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df_encoded = pd.DataFrame(ordinal_encoder.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Vérification des colonnes non numériques\n",
    "non_numeric_cols = df_encoded.select_dtypes(exclude=[np.number]).columns\n",
    "df_encoded.drop(columns=non_numeric_cols, inplace=True)\n",
    "\n",
    "# Gestion des valeurs manquantes avec SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(df_encoded.drop(columns=['TARGET'])), columns=df_encoded.drop(columns=['TARGET']).columns)\n",
    "\n",
    "# Séparation des caractéristiques et la cible\n",
    "y = df_encoded['TARGET']\n",
    "\n",
    "# Séparation des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définir le modèle XGBoost avec ses paramètres\n",
    "model = XGBClassifier(scale_pos_weight=10, random_state=42)\n",
    "params = {'n_estimators': [50, 100], 'max_depth': [3, 6, 9]}\n",
    "\n",
    "# Configurer l'expérience MLflow\n",
    "mlflow.set_tracking_uri(mlflow_url)\n",
    "mlflow.set_experiment(\"Credit Scoring Experiment\")\n",
    "\n",
    "# Échantillonner les données\n",
    "sample_size = 0.1 \n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=(1 - sample_size), random_state=42)\n",
    "X_test_sample, _, y_test_sample, _ = train_test_split(X_test, y_test, test_size=(1 - sample_size), random_state=42)\n",
    "\n",
    "# Entraînement du modèle XGBoost obtention des meilleurs paramètres\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    print(\"Entraînement du modèle XGBoost...\")\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='f1', cv=3)\n",
    "    grid_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "    # Loguer les paramètres dans MLflow\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Affichage des meilleurs paramètres et le score F1\n",
    "    print(f\"Meilleurs paramètres pour XGBoost: {grid_search.best_params_}\")\n",
    "    print(f\"Score F1 moyen sur le jeu de validation: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # Utilisation du meilleur modèle pour les prédictions\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_sample)\n",
    "\n",
    "    # Évaluation du modèle avec le meilleur seuil pour minimiser le coût métier\n",
    "    y_prob = best_model.predict_proba(X_test_sample)[:, 1]\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    costs = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded = (y_prob > threshold).astype(int)\n",
    "        fp = np.sum((y_pred_thresholded == 1) & (y_test_sample == 0)) * cost_fp\n",
    "        fn = np.sum((y_pred_thresholded == 0) & (y_test_sample == 1)) * cost_fn\n",
    "        total_cost = fp + fn\n",
    "        costs.append(total_cost)\n",
    "\n",
    "    best_threshold = thresholds[np.argmin(costs)]\n",
    "    print(f\"Meilleur seuil pour minimiser le coût métier avec XGBoost: {best_threshold}\")\n",
    "\n",
    "    y_pred_best_threshold = (y_prob > best_threshold).astype(int)\n",
    "\n",
    "    # Affichage du rapport de classification et de la matrice de confusion\n",
    "    classification_report_str = classification_report(y_test_sample, y_pred_best_threshold)\n",
    "    confusion_matrix_str = confusion_matrix(y_test_sample, y_pred_best_threshold)\n",
    "\n",
    "    print(f\"Rapport de classification avec le meilleur seuil pour XGBoost:\")\n",
    "    print(classification_report_str)\n",
    "\n",
    "    print(f\"Matrice de confusion avec le meilleur seuil pour XGBoost:\")\n",
    "    print(confusion_matrix_str)\n",
    "    print()\n",
    "\n",
    "    # Loguer les métriques et les résultats dans MLflow\n",
    "    mlflow.log_metric(\"best_score_f1\", grid_search.best_score_)\n",
    "    mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "    mlflow.log_text(classification_report_str, \"classification_report.txt\")\n",
    "    mlflow.log_text(str(confusion_matrix_str), \"confusion_matrix.txt\")\n",
    "\n",
    "    # Loguer le modèle\n",
    "    model_path = 'model/xgboost_model.pkl'\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "    # Sauvegarder le modèle dans un fichier .pkl\n",
    "    joblib.dump(best_model, model_path)\n",
    "\n",
    "# Sauvegarder le prétraitement dans un fichier .pkl\n",
    "preprocessing_pipeline = {\n",
    "    'ordinal_encoder': ordinal_encoder,\n",
    "    'imputer': imputer\n",
    "}\n",
    "\n",
    "preprocessing_path = 'preprocessing/preprocessing_pipeline.pkl'\n",
    "os.makedirs(os.path.dirname(preprocessing_path), exist_ok=True)\n",
    "joblib.dump(preprocessing_pipeline, preprocessing_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du modèle XGBoost...\n",
    "Meilleurs paramètres pour XGBoost: {'max_depth': 3, 'n_estimators': 100}\n",
    "Score F1 moyen sur le jeu de validation: 0.289\n",
    "Meilleur seuil pour minimiser le coût métier avec XGBoost: 0.494949494949495\n",
    "Rapport de classification avec le meilleur seuil pour XGBoost:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      0.79      0.87      5663\n",
    "         1.0       0.20      0.59      0.29       486\n",
    "\n",
    "    accuracy                           0.78      6149\n",
    "    \n",
    "   macro avg       0.58      0.69      0.58      6149\n",
    "weighted avg       0.90      0.78      0.82      6149\n",
    "\n",
    "Matrice de confusion avec le meilleur seuil pour XGBoost:\n",
    "[[4491 1172]\n",
    " [ 200  286]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              0.0\n",
      "1              1.0\n",
      "2              2.0\n",
      "3              3.0\n",
      "4              4.0\n",
      "            ...   \n",
      "307487    307487.0\n",
      "307488    307488.0\n",
      "307489    307489.0\n",
      "307490    307490.0\n",
      "307491    307491.0\n",
      "Name: SK_ID_CURR, Length: 307492, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded['SK_ID_CURR'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
